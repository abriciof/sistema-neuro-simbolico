{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sistema neuro simbolico.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOAa5n3lz3GKlSGe2iF4odh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abriciof/sistema-neuro-simbolico/blob/main/sistema_neuro_simbolico.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 游뿩 Implementa칞칚o do m칠todo de Aprendizagem Relacional no paradigma de Sistemas Neuro-Simb칩licos\n",
        "\n",
        "*Universidade Federal do Amazonas*<br>\n",
        "*Engenharia da Computa칞칚o*<br>\n",
        "*Intelig칡ncia Artificial Turma EC01 2021/1*<br>\n",
        "\n",
        "*   Fabr칤cio da Costa Guimar칚es - 21950515\n",
        "*   Laura Aguiar Martinho - 21952064\n",
        "*   Lorena Bastos Amazonas - 21952638\n",
        "*   Mattheus Smith Costa - 21954379"
      ],
      "metadata": {
        "id": "majhimkEr7sj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bibliotecas"
      ],
      "metadata": {
        "id": "lIGMFRCWZb2U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.contrib.layers import fully_connected\n",
        "from math import floor, ceil\n",
        "from pylab import rcParams\n",
        "from time import gmtime, strftime"
      ],
      "metadata": {
        "id": "EAI5r4VpzhyU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf84e530-f5db-4665-bb4a-ed68d99e30a5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importando e separando a base \n",
        "Necess치rio: *(base-positivos-negativos.csv)*"
      ],
      "metadata": {
        "id": "KFERvJsxZr2N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Codificar one-hot\n",
        "def encode(series):\n",
        "    return  pd.get_dummies(series.astype(str))\n",
        "\n",
        "# Lendo o csv da base\n",
        "df = pd.read_csv('/content/base-positivos-negativos.csv')\n",
        "dados = df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Predicados\n",
        "predicados = dados.drop('hd(X)',1)\n",
        "\n",
        "# Labels\n",
        "labels = encode(dados['hd(X)'])\n",
        "\n",
        "# Separando a base entre treino 90% e teste 10%\n",
        "tam_treino = 0.9\n",
        "cnt_treino = floor(predicados.shape[0] * tam_treino)\n",
        "x_treino = predicados.iloc[0:cnt_treino].values\n",
        "y_treino = labels.iloc[0:cnt_treino].values\n",
        "x_teste =  predicados.iloc[cnt_treino:].values\n",
        "y_teste = labels.iloc[cnt_treino:].values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sqmxzt-9ZqBD",
        "outputId": "5c4cbb77-1f44-4caf-e5fc-86be354215fd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Estrutura da Rede Neural Artificial"
      ],
      "metadata": {
        "id": "F-PNhVpChaxK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "taxa_aprendizado = 0.01\n",
        "X = tf.placeholder(tf.float32, shape=(None, x_treino.shape[1]), name=\"X\")\n",
        "y = tf.placeholder(tf.int64,shape=(None,2), name=\"y\")\n",
        "\n",
        "# Estrutura da Rede Neural Artificial\n",
        "with tf.name_scope(\"rn\"):\n",
        "    camada_1 = fully_connected(X, x_treino.shape[1], scope=\"camada_1\")\n",
        "    camada_2 = fully_connected(camada_1, predicados.shape[0], scope=\"camada_2\")\n",
        "    saida = fully_connected(camada_2, 2, scope=\"saida\", activation_fn=None)\n",
        "\n",
        "# Opera칞칫es de Treino\n",
        "with tf.name_scope(\"fcusto\"):\n",
        "    y_float = tf.cast(y, tf.float32)\n",
        "    sigmoidtropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_float, logits=saida)\n",
        "    custo = tf.reduce_mean(sigmoidtropy, name=\"custo\")\n",
        "\n",
        "with tf.name_scope(\"treino\"):\n",
        "    otimizador = tf.train.GradientDescentOptimizer(taxa_aprendizado)\n",
        "op_treino = otimizador.minimize(custo)\n",
        "\n",
        "with tf.name_scope(\"eval\"):\n",
        "    previsao_correta = tf.equal(tf.argmax(saida,1), tf.argmax(y,1))\n",
        "eficiencia = tf.reduce_mean(tf.cast(previsao_correta, \"float\"))"
      ],
      "metadata": {
        "id": "PVsu4mo10Scd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a61e501a-8c81-4272-dac0-09cf1d6be26a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/layers/python/layers/layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Treino e testes"
      ],
      "metadata": {
        "id": "GJ4qcvCQxeC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()\n",
        "n_epocas = 15\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  init.run()\n",
        "  for epoca in range(n_epocas):\n",
        "    particao_total = int(len(x_treino) / 1)\n",
        "    x_parts = np.array_split(x_treino, particao_total)\n",
        "    y_parts = np.array_split(y_treino, particao_total)\n",
        "    for i in range(particao_total):\n",
        "      part_x, part_y = x_parts[i], y_parts[i]\n",
        "      sess.run(op_treino,feed_dict={X: part_x, y: part_y})\n",
        "      acc_treino = eficiencia.eval(feed_dict={X: part_x, y: part_y})\n",
        "      acc_teste = eficiencia.eval(feed_dict={X: x_teste, y: y_teste})\n",
        "    if epoca % 1 == 0:\n",
        "        print(\"칄poca:\", epoca+1,\"- Acur치cia teste:\" ,acc_teste)\n",
        "    x_t = np.array_split(x_teste, x_teste.shape[0])\n",
        "    y_t = np.array_split(y_teste, y_teste.shape[0])\n",
        "  for k in range(len(x_t)):\n",
        "      x_t2, y_t2 = x_t[k], y_t[k]\n",
        "      predicao = ''\n",
        "      label = ''\n",
        "\n",
        "      if (y_t2.item(0) == 1):\n",
        "        label = 'falso'\n",
        "      elif(y_t2.item(1) == 1):\n",
        "        label = 'verdadeiro'\n",
        "\n",
        "      pred = saida.eval(feed_dict={X:x_t2})\n",
        "      if (pred.item(0) > pred.item(1)):\n",
        "        predicao = 'falso'\n",
        "      elif(pred.item(1) > pred.item(0)):\n",
        "        predicao = 'verdadeiro'\n",
        "\n",
        "      print()\n",
        "      print(f'\\n{x_t2}')\n",
        "      print(f'predi칞칚o -> {pred} {predicao}')\n",
        "      print(f'label -> {y_t2} {label}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dREJuI9i_suY",
        "outputId": "a6704d72-a771-458d-af20-5407ef67b00b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "칄poca: 1 - Acur치cia teste: 0.6\n",
            "칄poca: 2 - Acur치cia teste: 0.6\n",
            "칄poca: 3 - Acur치cia teste: 0.6\n",
            "칄poca: 4 - Acur치cia teste: 0.6\n",
            "칄poca: 5 - Acur치cia teste: 0.6\n",
            "칄poca: 6 - Acur치cia teste: 0.6\n",
            "칄poca: 7 - Acur치cia teste: 0.6\n",
            "칄poca: 8 - Acur치cia teste: 0.6\n",
            "칄poca: 9 - Acur치cia teste: 0.8\n",
            "칄poca: 10 - Acur치cia teste: 0.8\n",
            "칄poca: 11 - Acur치cia teste: 1.0\n",
            "칄poca: 12 - Acur치cia teste: 1.0\n",
            "칄poca: 13 - Acur치cia teste: 1.0\n",
            "칄poca: 14 - Acur치cia teste: 1.0\n",
            "칄poca: 15 - Acur치cia teste: 1.0\n",
            "\n",
            "\n",
            "[[1 0 0 1 1 0 0 0 0 0 0 1]]\n",
            "predi칞칚o -> [[-0.42527854  0.3641236 ]] verdadeiro\n",
            "label -> [[0 1]] verdadeiro\n",
            "\n",
            "\n",
            "[[0 1 0 1 1 0 0 0 1 1 0 0]]\n",
            "predi칞칚o -> [[-0.73514104  0.5966549 ]] verdadeiro\n",
            "label -> [[0 1]] verdadeiro\n",
            "\n",
            "\n",
            "[[1 0 0 1 0 1 0 0 1 1 1 0]]\n",
            "predi칞칚o -> [[ 0.17873408 -0.27969512]] falso\n",
            "label -> [[1 0]] falso\n",
            "\n",
            "\n",
            "[[0 1 0 1 1 0 1 1 0 0 0 0]]\n",
            "predi칞칚o -> [[-1.1805335  0.9256139]] verdadeiro\n",
            "label -> [[0 1]] verdadeiro\n",
            "\n",
            "\n",
            "[[0 1 0 1 0 1 1 1 0 0 0 0]]\n",
            "predi칞칚o -> [[ 0.51593375 -0.31528124]] falso\n",
            "label -> [[1 0]] falso\n"
          ]
        }
      ]
    }
  ]
}